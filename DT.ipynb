{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a DT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 0.88129\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def entropy(s):\n",
    "    counts = np.bincount(s)\n",
    "    percentages = counts / len(s)\n",
    "    \n",
    "    entropy = 0\n",
    "    for pct in percentages:\n",
    "        if pct > 0:\n",
    "            entropy += pct * np.log2(pct)\n",
    "    return -entropy\n",
    "\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "print(f'Entropy: {np.round(entropy(s), 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 2.1\n"
     ]
    }
   ],
   "source": [
    "def rss(s):\n",
    "    return np.sum((s - np.mean(s)) ** 2)\n",
    "\n",
    "s = np.array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
    "print(f'Residual sum of squares: {rss(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain: 3.0\n"
     ]
    }
   ],
   "source": [
    "def information_gain(parent, left_child, right_child, classifier=True):\n",
    "    num_left = len(left_child) / len(parent)\n",
    "    num_right = len(right_child) / len(parent)\n",
    "    \n",
    "    if classifier:\n",
    "        gain = entropy(parent) - (num_left * entropy(left_child) + num_right * entropy(right_child))\n",
    "        return gain\n",
    "    else:\n",
    "        gain = rss(parent) - (num_left * rss(left_child) + num_right * rss(right_child))\n",
    "        return gain\n",
    "\n",
    "parent = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "left_child = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "right_child = [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "print(f'Information gain: {np.round(information_gain(parent, left_child, right_child, False), 5)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    Helper class which implements a single tree node.\n",
    "    '''\n",
    "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.data_left = data_left\n",
    "        self.data_right = data_right\n",
    "        self.gain = gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    '''\n",
    "    Class which implements a decision tree classifier algorithm.\n",
    "    '''\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, classifier=True):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.classifier = classifier\n",
    "        self.root = None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _entropy(s):\n",
    "        '''\n",
    "        Helper function, calculates entropy from an array of integer values.\n",
    "        \n",
    "        :param s: list\n",
    "        :return: float, entropy value\n",
    "        '''\n",
    "        # Convert to integers to avoid runtime errors\n",
    "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
    "        # Probabilities of each class label\n",
    "        percentages = counts / len(s)\n",
    "\n",
    "        # Caclulate entropy\n",
    "        entropy = 0\n",
    "        for pct in percentages:\n",
    "            if pct > 0:\n",
    "                entropy += pct * np.log2(pct)\n",
    "        return -entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def _rss(s):\n",
    "        '''\n",
    "        Helper function, calculates residual sum of squares from an array of integer values.\n",
    "        \n",
    "        :param s: list\n",
    "        :return: float, residual sum of squares\n",
    "        '''\n",
    "        return np.sum((s - np.mean(s)) ** 2)\n",
    "    \n",
    "    def _information_gain(self, parent, left_child, right_child):\n",
    "        '''\n",
    "        Helper function, calculates information gain from a parent and two child nodes.\n",
    "        \n",
    "        :param parent: list, the parent node\n",
    "        :param left_child: list, left child of a parent\n",
    "        :param right_child: list, right child of a parent\n",
    "        :param classifier: bool, whether the tree is a classifier or a regressor\n",
    "        :return: float, information gain\n",
    "        '''\n",
    "        num_left = len(left_child) / len(parent)\n",
    "        num_right = len(right_child) / len(parent)\n",
    "        \n",
    "        if self.classifier:\n",
    "            # One-liner which implements the previously discussed formula\n",
    "            return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
    "        \n",
    "        else:\n",
    "            # One-liner which implements the previously discussed formula\n",
    "            return self._rss(parent) - (num_left * self._rss(left_child) + num_right * self._rss(right_child))\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        '''\n",
    "        Helper function, calculates the best split for given features and target\n",
    "        \n",
    "        :param X: np.array, features\n",
    "        :param y: np.array or list, target\n",
    "        :return: dict\n",
    "        '''\n",
    "        best_split = {}\n",
    "        best_info_gain = -1\n",
    "        n_rows, n_cols = X.shape\n",
    "        \n",
    "        # For every dataset feature\n",
    "        for f_idx in range(n_cols):\n",
    "            X_curr = X[:, f_idx]\n",
    "            # For every unique value of that feature\n",
    "            for threshold in np.unique(X_curr):\n",
    "                # Construct a dataset and split it to the left and right parts\n",
    "                # Left part includes records lower or equal to the threshold\n",
    "                # Right part includes records higher than the threshold\n",
    "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
    "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
    "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
    "\n",
    "                # Do the calculation only if there's data in both subsets\n",
    "                if len(df_left) > 0 and len(df_right) > 0:\n",
    "                    # Obtain the value of the target variable for subsets\n",
    "                    y = df[:, -1]\n",
    "                    y_left = df_left[:, -1]\n",
    "                    y_right = df_right[:, -1]\n",
    "\n",
    "                    # Caclulate the information gain and save the split parameters\n",
    "                    # if the current split if better then the previous best\n",
    "                    gain = self._information_gain(y, y_left, y_right)\n",
    "                    if gain > best_info_gain:\n",
    "                        best_split = {\n",
    "                            'feature_index': f_idx,\n",
    "                            'threshold': threshold,\n",
    "                            'df_left': df_left,\n",
    "                            'df_right': df_right,\n",
    "                            'gain': gain\n",
    "                        }\n",
    "                        best_info_gain = gain\n",
    "        return best_split\n",
    "    \n",
    "    def _build(self, X, y, depth=0):\n",
    "        '''\n",
    "        Helper recursive function, used to build a decision tree from the input data.\n",
    "        \n",
    "        :param X: np.array, features\n",
    "        :param y: np.array or list, target\n",
    "        :param depth: current depth of a tree, used as a stopping criteria\n",
    "        :return: Node\n",
    "        '''\n",
    "        n_rows, n_cols = X.shape\n",
    "        \n",
    "        # Check to see if a node should be leaf node\n",
    "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
    "            # Get the best split\n",
    "            best = self._best_split(X, y)\n",
    "            # If the split isn't pure\n",
    "            if best['gain'] > 0:\n",
    "                # Build a tree on the left\n",
    "                left = self._build(\n",
    "                    X=best['df_left'][:, :-1], \n",
    "                    y=best['df_left'][:, -1], \n",
    "                    depth=depth + 1\n",
    "                )\n",
    "                right = self._build(\n",
    "                    X=best['df_right'][:, :-1], \n",
    "                    y=best['df_right'][:, -1], \n",
    "                    depth=depth + 1\n",
    "                )\n",
    "                return Node(\n",
    "                    feature=best['feature_index'], \n",
    "                    threshold=best['threshold'], \n",
    "                    data_left=left, \n",
    "                    data_right=right, \n",
    "                    gain=best['gain']\n",
    "                )\n",
    "        # Leaf node - value is the most common target value \n",
    "        return Node(\n",
    "            value=Counter(y).most_common(1)[0][0]\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Function used to train a decision tree classifier model.\n",
    "        \n",
    "        :param X: np.array, features\n",
    "        :param y: np.array or list, target\n",
    "        :return: None\n",
    "        '''\n",
    "        # Call a recursive function to build the tree\n",
    "        self.root = self._build(X, y)\n",
    "        \n",
    "    def _predict(self, x, tree):\n",
    "        '''\n",
    "        Helper recursive function, used to predict a single instance (tree traversal).\n",
    "        \n",
    "        :param x: single observation\n",
    "        :param tree: built tree\n",
    "        :return: float, predicted class\n",
    "        '''\n",
    "        # Leaf node\n",
    "        if tree.value != None:\n",
    "            return tree.value\n",
    "        feature_value = x[tree.feature]\n",
    "        \n",
    "        # Go to the left\n",
    "        if feature_value <= tree.threshold:\n",
    "            return self._predict(x=x, tree=tree.data_left)\n",
    "        \n",
    "        # Go to the right\n",
    "        if feature_value > tree.threshold:\n",
    "            return self._predict(x=x, tree=tree.data_right)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Function used to classify new instances.\n",
    "        \n",
    "        :param X: np.array, features\n",
    "        :return: np.array, predicted classes\n",
    "        '''\n",
    "        # Call the _predict() function for every observation\n",
    "        return [self._predict(x, self.root) for x in X]\n",
    "\n",
    "    def text_representation(self):\n",
    "        '''\n",
    "        Function that prints a written description of the decision tree.\n",
    "        '''\n",
    "        print(\"----------------------------------| Tree |----------------------------------\")\n",
    "        print(\"Root\")\n",
    "        self._text_representation(self.root)\n",
    "        print(\"----------------------------------------------------------------------------\")\n",
    "\n",
    "    def _text_representation(self, tree, link_str: str=\"\"):\n",
    "        '''\n",
    "        Recursive function that prints the different leaves and nodes of the tree.\n",
    "        Each call of this function prints either the class if this tree is a leaf, or the 2 next nodes otherwise.\n",
    "\n",
    "        :param tree: tree or part of the tree being described\n",
    "        :param link_str: string containing the spaces and edge to position the current tree.\n",
    "        '''\n",
    "        if tree.value != None:\n",
    "            print(link_str + f\"└──⤇ Class: {int(tree.value)}\")\n",
    "            return\n",
    "        threshold = round(tree.threshold, 4)\n",
    "        print(link_str + f\"├─── [Feature {tree.feature}] <= {threshold}\")\n",
    "        self._text_representation(tree.data_left, link_str + \"│   \")\n",
    "        print(link_str + f\"└─── [Feature {tree.feature}] >  {threshold}\")\n",
    "        self._text_representation(tree.data_right, link_str + \"    \")\n",
    "\n",
    "    def plot_partition(self, X, y=None, feature_x: int=0, feature_y: int=1, color_map: str=\"hsv\"):\n",
    "        '''\n",
    "        Function that plots the X other 2 features and the partition chosed during the training of the DT.\n",
    "        \n",
    "        :param X: array that contains the features.\n",
    "        :param y: array that contains the corresponding categories. If None, the categories will be predicted using the DT.\n",
    "        :param feature_x: index of the feature to use on the horizontal axis.\n",
    "        :param feature_y: index of the feature to use on the vertical axis.\n",
    "        :param color_map: string name corresponding to the standard color map name.\n",
    "        '''\n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        if not self.classifier:\n",
    "            print(\"Only a classifier decision tree can be plotted with this function.\")\n",
    "            return\n",
    "        if feature_x >= X.shape[1]:\n",
    "            print(\"Feature index {feature_x} is out of dataset X size {X.shape}\")\n",
    "        if feature_y >= X.shape[1]:\n",
    "            print(\"Feature index {feature_y} is out of dataset X size {X.shape}\")\n",
    "\n",
    "        if y is None:\n",
    "            y = self.predict(X)\n",
    "\n",
    "        categories = set(y)\n",
    "        cmap = plt.cm.get_cmap(color_map, len(categories))\n",
    "        dataframe = pd.DataFrame(zip(X[:, feature_x], X[:, feature_y], y), columns=['x', 'y', 'category'])\n",
    "        grouped = dataframe.groupby('category')\n",
    "        for index, (category, group) in enumerate(grouped):\n",
    "            plt.scatter(group[\"x\"], group[\"y\"], color=cmap(index), label=str(category))\n",
    "        self._draw_lines(\n",
    "            self.root,\n",
    "            feature_x,\n",
    "            feature_y,\n",
    "            dataframe[\"x\"].min(),\n",
    "            dataframe[\"x\"].max(),\n",
    "            dataframe[\"y\"].min(),\n",
    "            dataframe[\"y\"].max())\n",
    "        plt.xlabel(f\"Feature {feature_x}\")\n",
    "        plt.ylabel(f\"Feature {feature_y}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def _draw_lines(self, tree, feature_x, feature_y, x_min, x_max, y_min, y_max):\n",
    "        '''\n",
    "        Iterative function that draws the line between categories.\n",
    "\n",
    "        :param tree: tree or part of the tree currently studied.\n",
    "        :param feature_x: index of the feature to use on the horizontal axis.\n",
    "        :param feature_y: index of the feature to use on the vertical axis.\n",
    "        :param x_min: minimal value of the feature used on the horizontal axis in the studied area.\n",
    "        :param x_max: maximal value of the feature used on the horizontal axis in the studied area.\n",
    "        :param y_min: minimal value of the feature used on the vertical axis in the studied area.\n",
    "        :param y_max: maximal value of the feature used on the vertical axis in the studied area.\n",
    "        '''\n",
    "        if tree.value == None:\n",
    "            if tree.feature == feature_x:\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.plot([tree.threshold, tree.threshold], [y_min, y_max], color=\"black\")\n",
    "                self._draw_lines(tree.data_left, feature_x, feature_y, x_min, tree.threshold, y_min, y_max)\n",
    "                self._draw_lines(tree.data_right, feature_x, feature_y, tree.threshold, x_max, y_min, y_max)\n",
    "                return\n",
    "            \n",
    "            if tree.feature == feature_y:\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.plot([x_min, x_max], [tree.threshold, tree.threshold], color=\"black\")\n",
    "                self._draw_lines(tree.data_left, feature_x, feature_y, x_min, x_max, y_min, tree.threshold)\n",
    "                self._draw_lines(tree.data_right, feature_x, feature_y, x_min, x_max, tree.threshold, y_max)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our DT:\n",
      "----------------------------------| Tree |----------------------------------\n",
      "Root\n",
      "├─── [Feature 2] <= 1.9\n",
      "│   └──⤇ Class: 0\n",
      "└─── [Feature 2] >  1.9\n",
      "    ├─── [Feature 2] <= 4.7\n",
      "    │   ├─── [Feature 3] <= 1.6\n",
      "    │   │   └──⤇ Class: 1\n",
      "    │   └─── [Feature 3] >  1.6\n",
      "    │       └──⤇ Class: 2\n",
      "    └─── [Feature 2] >  4.7\n",
      "        ├─── [Feature 3] <= 1.7\n",
      "        │   ├─── [Feature 2] <= 4.9\n",
      "        │   │   └──⤇ Class: 1\n",
      "        │   └─── [Feature 2] >  4.9\n",
      "        │       ├─── [Feature 3] <= 1.5\n",
      "        │       │   └──⤇ Class: 2\n",
      "        │       └─── [Feature 3] >  1.5\n",
      "        │           ├─── [Feature 0] <= 6.7\n",
      "        │           │   └──⤇ Class: 1\n",
      "        │           └─── [Feature 0] >  6.7\n",
      "        │               └──⤇ Class: 2\n",
      "        └─── [Feature 3] >  1.7\n",
      "            ├─── [Feature 2] <= 4.8\n",
      "            │   ├─── [Feature 0] <= 5.9\n",
      "            │   │   └──⤇ Class: 1\n",
      "            │   └─── [Feature 0] >  5.9\n",
      "            │       └──⤇ Class: 2\n",
      "            └─── [Feature 2] >  4.8\n",
      "                └──⤇ Class: 2\n",
      "----------------------------------------------------------------------------\n",
      "Accuracy with our DT:  1.0\n",
      "\n",
      "Sklearn DT:\n",
      "|--- feature_2 <= 2.45\n",
      "|   |--- class: 0\n",
      "|--- feature_2 >  2.45\n",
      "|   |--- feature_2 <= 4.75\n",
      "|   |   |--- feature_3 <= 1.65\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- feature_3 >  1.65\n",
      "|   |   |   |--- class: 2\n",
      "|   |--- feature_2 >  4.75\n",
      "|   |   |--- feature_3 <= 1.75\n",
      "|   |   |   |--- feature_2 <= 4.95\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_2 >  4.95\n",
      "|   |   |   |   |--- feature_3 <= 1.55\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_3 >  1.55\n",
      "|   |   |   |   |   |--- feature_0 <= 6.95\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_0 >  6.95\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |--- feature_3 >  1.75\n",
      "|   |   |   |--- feature_2 <= 4.85\n",
      "|   |   |   |   |--- feature_1 <= 3.10\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_1 >  3.10\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_2 >  4.85\n",
      "|   |   |   |   |--- class: 2\n",
      "\n",
      "Accuracy with sklearn DT:  1.0\n",
      "Example of our DT other the features 2 and 3:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTree(classifier=True)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"Our DT:\")\n",
    "model.text_representation()\n",
    "\n",
    "print('Accuracy with our DT: ', accuracy_score(y_test, preds))\n",
    "\n",
    "sk_model = DecisionTreeClassifier()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_preds = sk_model.predict(X_test)\n",
    "\n",
    "print(\"\\nSklearn DT:\")\n",
    "print(tree.export_text(sk_model))\n",
    "\n",
    "print('Accuracy with sklearn DT: ', accuracy_score(y_test, sk_preds))\n",
    "\n",
    "print(\"Example of our DT other the features 2 and 3:\")\n",
    "model.plot_partition(X_train, y_train, feature_x=2, feature_y=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our DT:\n",
      "----------------------------------| Tree |----------------------------------\n",
      "Root\n",
      "├─ [Feature 2] <= 0.0046\n",
      "│      ├─ [Feature 8] <= -0.0109\n",
      "│      │      ├─ [Feature 3] <= -0.0126\n",
      "│      │      │      ├─ [Feature 6] <= 0.0118\n",
      "│      │      │      │      ├─ [Feature 8] <= -0.0358\n",
      "│      │      │      │      │      ├─ [Feature 3] <= -0.0401\n",
      "│      │      │      │      │      │      └──⤇ \u001b[34mClass: 88\u001b[0m\n",
      "│      │      │      │      │      └─ [Feature 3] >  -0.0401\n",
      "│      │      │      │      │             └──⤇ \u001b[32mClass: 71\u001b[0m\n",
      "│      │      │      │      └─ [Feature 8] >  -0.0358\n",
      "│      │      │      │             ├─ [Feature 0] <= -0.0527\n",
      "│      │      │      │             │      └──⤇ \u001b[35mClass: 104\u001b[0m\n",
      "│      │      │      │             └─ [Feature 0] >  -0.0527\n",
      "│      │      │      │                    └──⤇ \u001b[33mClass: 97\u001b[0m\n",
      "│      │      │      └─ [Feature 6] >  0.0118\n",
      "│      │      │             ├─ [Feature 4] <= -0.0442\n",
      "│      │      │             │      ├─ [Feature 6] <= 0.0266\n",
      "│      │      │             │      │      └──⤇ \u001b[33mClass: 137\u001b[0m\n",
      "│      │      │             │      └─ [Feature 6] >  0.0266\n",
      "│      │      │             │             └──⤇ \u001b[31mClass: 125\u001b[0m\n",
      "│      │      │             └─ [Feature 4] >  -0.0442\n",
      "│      │      │                    ├─ [Feature 3] <= -0.0298\n",
      "│      │      │                    │      └──⤇ \u001b[35mClass: 59\u001b[0m\n",
      "│      │      │                    └─ [Feature 3] >  -0.0298\n",
      "│      │      │                           └──⤇ \u001b[31mClass: 90\u001b[0m\n",
      "│      │      └─ [Feature 3] >  -0.0126\n",
      "│      │             ├─ [Feature 0] <= 0.0163\n",
      "│      │             │      ├─ [Feature 9] <= -0.0218\n",
      "│      │             │      │      ├─ [Feature 2] <= -0.0364\n",
      "│      │             │      │      │      └──⤇ \u001b[32mClass: 101\u001b[0m\n",
      "│      │             │      │      └─ [Feature 2] >  -0.0364\n",
      "│      │             │      │             └──⤇ \u001b[32mClass: 216\u001b[0m\n",
      "│      │             │      └─ [Feature 9] >  -0.0218\n",
      "│      │             │             ├─ [Feature 3] <= -0.0022\n",
      "│      │             │             │      └──⤇ \u001b[34mClass: 178\u001b[0m\n",
      "│      │             │             └─ [Feature 3] >  -0.0022\n",
      "│      │             │                    └──⤇ \u001b[35mClass: 49\u001b[0m\n",
      "│      │             └─ [Feature 0] >  0.0163\n",
      "│      │                    ├─ [Feature 8] <= -0.0295\n",
      "│      │                    │      ├─ [Feature 9] <= 0.0113\n",
      "│      │                    │      │      └──⤇ \u001b[32mClass: 71\u001b[0m\n",
      "│      │                    │      └─ [Feature 9] >  0.0113\n",
      "│      │                    │             └──⤇ \u001b[33mClass: 132\u001b[0m\n",
      "│      │                    └─ [Feature 8] >  -0.0295\n",
      "│      │                           ├─ [Feature 8] <= -0.016\n",
      "│      │                           │      └──⤇ \u001b[32mClass: 81\u001b[0m\n",
      "│      │                           └─ [Feature 8] >  -0.016\n",
      "│      │                                  └──⤇ \u001b[34mClass: 53\u001b[0m\n",
      "│      └─ [Feature 8] >  -0.0109\n",
      "│             ├─ [Feature 8] <= 0.0213\n",
      "│             │      ├─ [Feature 7] <= 0.0284\n",
      "│             │      │      ├─ [Feature 5] <= -0.0289\n",
      "│             │      │      │      ├─ [Feature 9] <= 0.0196\n",
      "│             │      │      │      │      └──⤇ \u001b[33mClass: 252\u001b[0m\n",
      "│             │      │      │      └─ [Feature 9] >  0.0196\n",
      "│             │      │      │             └──⤇ \u001b[32mClass: 86\u001b[0m\n",
      "│             │      │      └─ [Feature 5] >  -0.0289\n",
      "│             │      │             ├─ [Feature 0] <= 0.0381\n",
      "│             │      │             │      └──⤇ \u001b[34mClass: 88\u001b[0m\n",
      "│             │      │             └─ [Feature 0] >  0.0381\n",
      "│             │      │                    └──⤇ \u001b[31mClass: 185\u001b[0m\n",
      "│             │      └─ [Feature 7] >  0.0284\n",
      "│             │             ├─ [Feature 2] <= -0.0127\n",
      "│             │             │      ├─ [Feature 0] <= -0.0091\n",
      "│             │             │      │      └──⤇ \u001b[31mClass: 150\u001b[0m\n",
      "│             │             │      └─ [Feature 0] >  -0.0091\n",
      "│             │             │             └──⤇ \u001b[33mClass: 102\u001b[0m\n",
      "│             │             └─ [Feature 2] >  -0.0127\n",
      "│             │                    ├─ [Feature 5] <= 0.0049\n",
      "│             │                    │      └──⤇ \u001b[33mClass: 257\u001b[0m\n",
      "│             │                    └─ [Feature 5] >  0.0049\n",
      "│             │                           └──⤇ \u001b[35mClass: 179\u001b[0m\n",
      "│             └─ [Feature 8] >  0.0213\n",
      "│                    ├─ [Feature 4] <= 0.0507\n",
      "│                    │      ├─ [Feature 8] <= 0.028\n",
      "│                    │      │      ├─ [Feature 6] <= -0.0397\n",
      "│                    │      │      │      └──⤇ \u001b[33mClass: 292\u001b[0m\n",
      "│                    │      │      └─ [Feature 6] >  -0.0397\n",
      "│                    │      │             └──⤇ \u001b[32mClass: 206\u001b[0m\n",
      "│                    │      └─ [Feature 8] >  0.028\n",
      "│                    │             ├─ [Feature 6] <= -0.025\n",
      "│                    │             │      └──⤇ \u001b[35mClass: 209\u001b[0m\n",
      "│                    │             └─ [Feature 6] >  -0.025\n",
      "│                    │                    └──⤇ \u001b[35mClass: 189\u001b[0m\n",
      "│                    └─ [Feature 4] >  0.0507\n",
      "│                           ├─ [Feature 8] <= 0.0451\n",
      "│                           │      ├─ [Feature 3] <= 0.0047\n",
      "│                           │      │      └──⤇ \u001b[32mClass: 116\u001b[0m\n",
      "│                           │      └─ [Feature 3] >  0.0047\n",
      "│                           │             └──⤇ \u001b[31mClass: 170\u001b[0m\n",
      "│                           └─ [Feature 8] >  0.0451\n",
      "│                                  ├─ [Feature 1] <= -0.0446\n",
      "│                                  │      └──⤇ \u001b[35mClass: 109\u001b[0m\n",
      "│                                  └─ [Feature 1] >  -0.0446\n",
      "│                                         └──⤇ \u001b[34mClass: 248\u001b[0m\n",
      "└─ [Feature 2] >  0.0046\n",
      "       ├─ [Feature 3] <= 0.015\n",
      "       │      ├─ [Feature 8] <= 0.0261\n",
      "       │      │      ├─ [Feature 2] <= 0.0304\n",
      "       │      │      │      ├─ [Feature 0] <= -0.0091\n",
      "       │      │      │      │      ├─ [Feature 8] <= -0.0307\n",
      "       │      │      │      │      │      └──⤇ \u001b[31mClass: 60\u001b[0m\n",
      "       │      │      │      │      └─ [Feature 8] >  -0.0307\n",
      "       │      │      │      │             └──⤇ \u001b[31mClass: 210\u001b[0m\n",
      "       │      │      │      └─ [Feature 0] >  -0.0091\n",
      "       │      │      │             ├─ [Feature 6] <= -0.0397\n",
      "       │      │      │             │      └──⤇ \u001b[35mClass: 174\u001b[0m\n",
      "       │      │      │             └─ [Feature 6] >  -0.0397\n",
      "       │      │      │                    └──⤇ \u001b[33mClass: 197\u001b[0m\n",
      "       │      │      └─ [Feature 2] >  0.0304\n",
      "       │      │             ├─ [Feature 3] <= -0.0263\n",
      "       │      │             │      ├─ [Feature 6] <= -0.0139\n",
      "       │      │             │      │      └──⤇ \u001b[33mClass: 167\u001b[0m\n",
      "       │      │             │      └─ [Feature 6] >  -0.0139\n",
      "       │      │             │             └──⤇ \u001b[31mClass: 85\u001b[0m\n",
      "       │      │             └─ [Feature 3] >  -0.0263\n",
      "       │      │                    ├─ [Feature 9] <= 0.0403\n",
      "       │      │                    │      └──⤇ \u001b[32mClass: 141\u001b[0m\n",
      "       │      │                    └─ [Feature 9] >  0.0403\n",
      "       │      │                           └──⤇ \u001b[35mClass: 84\u001b[0m\n",
      "       │      └─ [Feature 8] >  0.0261\n",
      "       │             ├─ [Feature 9] <= 0.0072\n",
      "       │             │      ├─ [Feature 8] <= 0.0451\n",
      "       │             │      │      ├─ [Feature 9] <= -0.0176\n",
      "       │             │      │      │      └──⤇ \u001b[33mClass: 242\u001b[0m\n",
      "       │             │      │      └─ [Feature 9] >  -0.0176\n",
      "       │             │      │             └──⤇ \u001b[34mClass: 128\u001b[0m\n",
      "       │             │      └─ [Feature 8] >  0.0451\n",
      "       │             │             ├─ [Feature 5] <= 0.0532\n",
      "       │             │             │      └──⤇ \u001b[34mClass: 68\u001b[0m\n",
      "       │             │             └─ [Feature 5] >  0.0532\n",
      "       │             │                    └──⤇ \u001b[32mClass: 131\u001b[0m\n",
      "       │             └─ [Feature 9] >  0.0072\n",
      "       │                    ├─ [Feature 0] <= 0.0018\n",
      "       │                    │      ├─ [Feature 6] <= -0.0471\n",
      "       │                    │      │      └──⤇ \u001b[34mClass: 268\u001b[0m\n",
      "       │                    │      └─ [Feature 6] >  -0.0471\n",
      "       │                    │             └──⤇ \u001b[33mClass: 192\u001b[0m\n",
      "       │                    └─ [Feature 0] >  0.0018\n",
      "       │                           ├─ [Feature 0] <= 0.0308\n",
      "       │                           │      └──⤇ \u001b[33mClass: 262\u001b[0m\n",
      "       │                           └─ [Feature 0] >  0.0308\n",
      "       │                                  └──⤇ \u001b[31mClass: 225\u001b[0m\n",
      "       └─ [Feature 3] >  0.015\n",
      "              ├─ [Feature 2] <= 0.0455\n",
      "              │      ├─ [Feature 2] <= 0.0197\n",
      "              │      │      ├─ [Feature 4] <= 0.0177\n",
      "              │      │      │      ├─ [Feature 3] <= 0.0391\n",
      "              │      │      │      │      └──⤇ \u001b[31mClass: 265\u001b[0m\n",
      "              │      │      │      └─ [Feature 3] >  0.0391\n",
      "              │      │      │             └──⤇ \u001b[34mClass: 178\u001b[0m\n",
      "              │      │      └─ [Feature 4] >  0.0177\n",
      "              │      │             ├─ [Feature 8] <= 0.0407\n",
      "              │      │             │      └──⤇ \u001b[35mClass: 144\u001b[0m\n",
      "              │      │             └─ [Feature 8] >  0.0407\n",
      "              │      │                    └──⤇ \u001b[35mClass: 139\u001b[0m\n",
      "              │      └─ [Feature 2] >  0.0197\n",
      "              │             ├─ [Feature 8] <= 0.0086\n",
      "              │             │      ├─ [Feature 4] <= -0.0607\n",
      "              │             │      │      └──⤇ \u001b[33mClass: 52\u001b[0m\n",
      "              │             │      └─ [Feature 4] >  -0.0607\n",
      "              │             │             └──⤇ \u001b[31mClass: 175\u001b[0m\n",
      "              │             └─ [Feature 8] >  0.0086\n",
      "              │                    ├─ [Feature 2] <= 0.0315\n",
      "              │                    │      └──⤇ \u001b[32mClass: 281\u001b[0m\n",
      "              │                    └─ [Feature 2] >  0.0315\n",
      "              │                           └──⤇ \u001b[32mClass: 166\u001b[0m\n",
      "              └─ [Feature 2] >  0.0455\n",
      "                     ├─ [Feature 5] <= -0.0023\n",
      "                     │      ├─ [Feature 8] <= 0.028\n",
      "                     │      │      ├─ [Feature 0] <= 0.0054\n",
      "                     │      │      │      └──⤇ \u001b[31mClass: 280\u001b[0m\n",
      "                     │      │      └─ [Feature 0] >  0.0054\n",
      "                     │      │             └──⤇ \u001b[34mClass: 288\u001b[0m\n",
      "                     │      └─ [Feature 8] >  0.028\n",
      "                     │             ├─ [Feature 0] <= 0.0272\n",
      "                     │             │      └──⤇ \u001b[33mClass: 277\u001b[0m\n",
      "                     │             └─ [Feature 0] >  0.0272\n",
      "                     │                    └──⤇ \u001b[31mClass: 270\u001b[0m\n",
      "                     └─ [Feature 5] >  -0.0023\n",
      "                            ├─ [Feature 2] <= 0.0725\n",
      "                            │      ├─ [Feature 6] <= -0.0176\n",
      "                            │      │      └──⤇ \u001b[31mClass: 215\u001b[0m\n",
      "                            │      └─ [Feature 6] >  -0.0176\n",
      "                            │             └──⤇ \u001b[32mClass: 131\u001b[0m\n",
      "                            └─ [Feature 2] >  0.0725\n",
      "                                   ├─ [Feature 5] <= 0.0215\n",
      "                                   │      └──⤇ \u001b[32mClass: 261\u001b[0m\n",
      "                                   └─ [Feature 5] >  0.0215\n",
      "                                          └──⤇ \u001b[33mClass: 237\u001b[0m\n",
      "----------------------------------------------------------------------------\n",
      "MAE with our DT:  55.48314606741573\n",
      "MSE with our DT:  5044.741573033708\n",
      "MAE with sklearn DT:  55.651685393258425\n",
      "MSE with sklearn DT:  5195.494382022472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes['data']\n",
    "y = diabetes['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = DecisionTree(classifier=False)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"Our DT:\")\n",
    "model.text_representation()\n",
    "\n",
    "print('MAE with our DT: ', mean_absolute_error(y_test, preds))\n",
    "print('MSE with our DT: ', mean_squared_error(y_test, preds))\n",
    "\n",
    "sk_model = DecisionTreeRegressor()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_preds = sk_model.predict(X_test)\n",
    "\n",
    "print('MAE with sklearn DT: ', mean_absolute_error(y_test, sk_preds))\n",
    "print('MSE with sklearn DT: ', mean_squared_error(y_test, sk_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
